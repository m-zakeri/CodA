{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CodA: Source code analysis and synthesis toolkit By: Morteza Zakeri, Ph.D. candidate Systematic software testing and quality assurance tools can be built on top of compiler tools such as ANTLR, LLVM, JDT, and Roslyn, with techniques presented in this chapter. Compilers build a detailed model of application code as they validate the syntax and semantics of that code. While traditional compilers used such a model to build the executable output from the source code in a block box manner, the new generation of compilers provides APIs to access the internal details of this model, which can be utilized to build more reliable software. Software testing is more realistic with advanced support by compilers. There is no practical tool to measure and compute the path coverage in unit testing. Most open-source and commercial tools report the statement and branch coverage as statistics for the performed tests. CodA aims to provide a measurement apparatus of the path coverage based on the concept of prime paths in unit testing. First, the control flow graph (CFG) of the unit under test is extracted. Second, the prime path is extracted. Third, the code is instrumented to capture the covered path. Finally, the test data is generated and fed to the unit under test, and the prime path coverage is measured. The main challenge is how we can match the executed path with the prime path in order to find the test effectiveness. The CodA contains the following modules: Control flow graph extractor Prime path extractor Source code instrumentor Path coverage computation based on prime-path coverage Random test data generation","title":"Home"},{"location":"#coda-source-code-analysis-and-synthesis-toolkit","text":"By: Morteza Zakeri, Ph.D. candidate Systematic software testing and quality assurance tools can be built on top of compiler tools such as ANTLR, LLVM, JDT, and Roslyn, with techniques presented in this chapter. Compilers build a detailed model of application code as they validate the syntax and semantics of that code. While traditional compilers used such a model to build the executable output from the source code in a block box manner, the new generation of compilers provides APIs to access the internal details of this model, which can be utilized to build more reliable software. Software testing is more realistic with advanced support by compilers. There is no practical tool to measure and compute the path coverage in unit testing. Most open-source and commercial tools report the statement and branch coverage as statistics for the performed tests. CodA aims to provide a measurement apparatus of the path coverage based on the concept of prime paths in unit testing. First, the control flow graph (CFG) of the unit under test is extracted. Second, the prime path is extracted. Third, the code is instrumented to capture the covered path. Finally, the test data is generated and fed to the unit under test, and the prime path coverage is measured. The main challenge is how we can match the executed path with the prime path in order to find the test effectiveness. The CodA contains the following modules: Control flow graph extractor Prime path extractor Source code instrumentor Path coverage computation based on prime-path coverage Random test data generation","title":"CodA: Source code analysis and synthesis toolkit"},{"location":"benchmarks/","text":"Benchmarks Currently, we support C++/CPP 14 programs. The test_data directory contains various CPP code fragments and also some student projects written in CPP. A set of C++ projects we run CodA on them as the benchmark are available in the Benchmark repository .","title":"Benchmarks"},{"location":"benchmarks/#benchmarks","text":"Currently, we support C++/CPP 14 programs. The test_data directory contains various CPP code fragments and also some student projects written in CPP. A set of C++ projects we run CodA on them as the benchmark are available in the Benchmark repository .","title":"Benchmarks"},{"location":"analysis_modules/cfg/cfg_extractor/","text":"Control flow graph extractors CFG Extractor with ANTLR listener (version 1) ANTLR listener to build control flow graph (CFG) for C++ functions If a CPP file contains multiple function the CFG is created for each function. For each function in the source file the CFG is stored in a dot file which can be visualized with graphviz. Changelog: Version 0.2.0 Add writing the extracted CFG in dot file. Add visualization with pydot and graphviz Version 0.1.0 CFGInstListener __init__ ( self , common_token_stream , number_of_tokens , directory_name ) special :param common_token_stream: Source code in coda\\analysis\\cfg\\cfg_extractor_listener1.py def __init__ ( self , common_token_stream : CommonTokenStream , number_of_tokens , directory_name ): \"\"\" :param common_token_stream: \"\"\" self . cfg_path = 'CFGS/' + directory_name + '/' self . instrument_path = 'Instrument/' + directory_name + '/' self . block_dict = {} self . block_number = 0 self . block_start = 0 self . block_stop = 0 self . domain_name = 0 self . function_dict = {} self . select_junction_stack = [] self . select_decision_stack = [] self . iterate_junction_stack = [] self . iterate_stack = [] self . switch_junction_stack = [] self . switch_stack = [] self . switch_for_stack = [] self . has_jump_stack = [] self . has_default_stack = [] self . has_case_stack = [] self . try_stack = [] self . try_junction_stack = [] self . is_catch = False self . afterInsert = [ '' ] * number_of_tokens self . initial_nodes = set () self . final_nodes = set () self . label_dict = {} self . goto_dict = {} # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter . TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) enterStatement ( self , ctx ) DFS traversal of a statement subtree, rooted at ctx. If the statement is a branching condition insert a prob. :param ctx: :return: Source code in coda\\analysis\\cfg\\cfg_extractor_listener1.py def enterStatement ( self , ctx : CPP14_v2Parser . StatementContext ): \"\"\" DFS traversal of a statement subtree, rooted at ctx. If the statement is a branching condition insert a prob. :param ctx: :return: \"\"\" # do-while and range-for if isinstance ( ctx . parentCtx , ( CPP14_v2Parser . Iterationstatement4Context , CPP14_v2Parser . Iterationstatement2Context )): # if there is a compound statement after the branchning condition: body = ctx . compoundstatement () if body is not None : self . insertAfter ( body ) # if there is only one statement after the branchning condition then create a block. else : new_code = '{' new_code += ' \\n ' + self . logLine () + '; \\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) # one line while and for elif isinstance ( ctx . parentCtx , CPP14_v2Parser . IterationstatementContext ): self . block_number += 1 self . block_start = ctx . start . line # if there is a compound statement after the branchning condition: body = ctx . compoundstatement () if body is not None : self . insertAfter ( body ) # if there is only one statement after the branchning condition then create a block. else : new_code = '{' new_code += ' \\n ' + self . logLine () + '; \\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) elif isinstance ( ctx . parentCtx , ( CPP14_v2Parser . Selectionstatement1Context , CPP14_v2Parser . Selectionstatement2Context )): self . block_number += 1 self . addDecisionEdge () self . block_start = ctx . start . line self . has_jump_stack . append ( False ) # if there is a compound statement after the branchning condition: body = ctx . compoundstatement () if body is not None : self . insertAfter ( body ) # if there is only one statement after the branchning condition then create a block. else : new_code = '{' new_code += ' \\n ' + self . logLine () + '; \\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) elif isinstance ( ctx . parentCtx , CPP14_v2Parser . Selectionstatement3Context ): if ctx . compoundstatement () is None : new_code = '{ \\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) enterTranslationunit ( self , ctx ) Creating and open a text file for logging the instrumentation result :param ctx: :return: Source code in coda\\analysis\\cfg\\cfg_extractor_listener1.py def enterTranslationunit ( self , ctx : CPP14_v2Parser . TranslationunitContext ): \"\"\" Creating and open a text file for logging the instrumentation result :param ctx: :return: \"\"\" self . instrumented_source = open ( self . instrument_path + 'instrumented_source.cpp' , 'w' ) log_path = self . instrument_path + \"log_file.txt\" new_code = ' \\n #include <fstream> \\n std::ofstream logFile(\"log_file.txt\"); \\n\\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) self . domain_name = 0 exitFunctionbody1 ( self , ctx ) Insert a prob at the end of the function only if the function is void. :param ctx: :return: Source code in coda\\analysis\\cfg\\cfg_extractor_listener1.py def exitFunctionbody1 ( self , ctx : CPP14_v2Parser . Functionbody1Context ): \"\"\" Insert a prob at the end of the function only if the function is void. :param ctx: :return: \"\"\" if not self . has_jump_stack . pop (): self . block_stop = ctx . stop . line self . addNode () self . final_nodes . add ( self . block_number ) exitTranslationunit ( self , ctx ) Creating and open a text file for logging the instrumentation result :param ctx: :return: Source code in coda\\analysis\\cfg\\cfg_extractor_listener1.py def exitTranslationunit ( self , ctx : CPP14_v2Parser . TranslationunitContext ): \"\"\" Creating and open a text file for logging the instrumentation result :param ctx: :return: \"\"\" for i in range ( len ( self . afterInsert )): if self . afterInsert [ i ] != '' : self . token_stream_rewriter . insertAfter ( i , self . afterInsert [ i ]) self . instrumented_source . write ( self . token_stream_rewriter . getDefaultText ()) self . instrumented_source . close () functions_json = open ( self . cfg_path + 'functions.json' , 'w' ) json . dump ( self . function_dict , functions_json ) CFG Extractor with ANTLR listener (version 2) ANTLR listener to build control flow graph (CFG) for C++ functions The improved version of the cfg_extractor_listener1.py module Changelog: version 2.0.1 Refactor the module version 2.0.0 CFGInstListener __init__ ( self , common_token_stream , number_of_tokens , directory_name ) special :param common_token_stream: Source code in coda\\analysis\\cfg\\cfg_extractor_listener2.py def __init__ ( self , common_token_stream : CommonTokenStream , number_of_tokens , directory_name ): \"\"\" :param common_token_stream: \"\"\" self . cfg_path = 'extracted_cfgs/' + directory_name + '/' self . instrument_path = 'instrumented_programs/' + directory_name + '/' self . block_dict = {} self . block_number = 0 self . block_start = 0 self . block_stop = 0 self . domain_name = 0 self . function_dict = {} self . select_junction_stack = [] self . select_decision_stack = [] self . iterate_junction_stack = [] self . iterate_stack = [] self . switch_junction_stack = [] self . temp = [] self . switch_stack = [] self . switch_for_stack = [] self . has_jump_stack = [] self . is_for = [] self . is_while = [] self . is_doWhile = [] self . has_default_stack = [] self . has_case_stack = [] self . try_stack = [] self . try_junction_stack = [] self . is_catch = False self . throw_stack = [] self . afterInsert = [ '' ] * number_of_tokens self . initial_nodes = set () self . final_nodes = set () self . label_dict = {} self . goto_dict = {} # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter . TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) # create graph self . CFG_graph = nx . Graph () enterStatement ( self , ctx ) DFS traversal of a statement subtree, rooted at ctx. If the statement is a branching condition insert a prob. :param ctx: :return: Source code in coda\\analysis\\cfg\\cfg_extractor_listener2.py def enterStatement ( self , ctx : CPP14_v2Parser . StatementContext ): \"\"\" DFS traversal of a statement subtree, rooted at ctx. If the statement is a branching condition insert a prob. :param ctx: :return: \"\"\" # do-while and range-for # line 342(CPP14_v2Parser.Iterationstatement4Context) if isinstance ( ctx . parentCtx , ( CPP14_v2Parser . Iterationstatement2Context )): # if there is a compound statement after the branchning condition: body = ctx . compoundstatement () if body != None : self . insertAfter ( body ) # if there is only one statement after the branchning condition then create a block. else : new_code = '{' new_code += ' \\n ' + self . logLine () + '; \\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) # one line while and for elif isinstance ( ctx . parentCtx , CPP14_v2Parser . IterationstatementContext ): self . block_number += 1 self . block_start = ctx . start . line # if there is a compound statement after the branchning condition: body = ctx . compoundstatement () if body != None : self . insertAfter ( body ) # if there is only one statement after the branchning condition then create a block. else : new_code = '{' new_code += ' \\n ' + self . logLine () + '; \\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) elif isinstance ( ctx . parentCtx , ( CPP14_v2Parser . Selectionstatement1Context , CPP14_v2Parser . Selectionstatement2Context )): self . block_number += 1 self . addDecisionEdge () self . block_start = ctx . start . line self . has_jump_stack . append ( False ) # if there is a compound statement after the branchning condition: body = ctx . compoundstatement () if body != None : self . insertAfter ( body ) # if there is only one statement after the branchning condition then create a block. else : new_code = '{' new_code += ' \\n ' + self . logLine () + '; \\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) elif isinstance ( ctx . parentCtx , CPP14_v2Parser . Selectionstatement3Context ): if ctx . compoundstatement () == None : new_code = '{ \\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) enterTranslationunit ( self , ctx ) Creating and open a text file for logging the instrumentation result :param ctx: :return: Source code in coda\\analysis\\cfg\\cfg_extractor_listener2.py def enterTranslationunit ( self , ctx : CPP14_v2Parser . TranslationunitContext ): \"\"\" Creating and open a text file for logging the instrumentation result :param ctx: :return: \"\"\" self . instrumented_source = open ( self . instrument_path + 'instrumented_source.cpp' , 'w' ) log_path = self . instrument_path + \"log_file.txt\" new_code = ' \\n //in the name of allah \\n #include <fstream> \\n std::ofstream logFile(\"log_file.txt\"); \\n\\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) self . domain_name = 0 exitFunctionbody1 ( self , ctx ) Insert a prob at the end of the function only if the function is void. :param ctx: :return: Source code in coda\\analysis\\cfg\\cfg_extractor_listener2.py def exitFunctionbody1 ( self , ctx : CPP14_v2Parser . Functionbody1Context ): \"\"\" Insert a prob at the end of the function only if the function is void. :param ctx: :return: \"\"\" if not self . has_jump_stack . pop (): self . block_stop = ctx . stop . line self . addNode () self . final_nodes . add ( self . block_number ) exitTranslationunit ( self , ctx ) Creating and open a text file for logging the instrumentation result :param ctx: :return: Source code in coda\\analysis\\cfg\\cfg_extractor_listener2.py def exitTranslationunit ( self , ctx : CPP14_v2Parser . TranslationunitContext ): \"\"\" Creating and open a text file for logging the instrumentation result :param ctx: :return: \"\"\" for i in range ( len ( self . afterInsert )): if self . afterInsert [ i ] != '' : self . token_stream_rewriter . insertAfter ( i , self . afterInsert [ i ]) self . instrumented_source . write ( self . token_stream_rewriter . getDefaultText ()) self . instrumented_source . close () functions_json = open ( self . cfg_path + 'functions.json' , 'w' ) json . dump ( self . function_dict , functions_json ) CFG Extractor with ANTLR visitor ANTLR visitor to build control flow graph (CFG) for C++ functions The improved version of the cfg_extractor_listener1.py module Changelog: version 1.0.1 Refactor the module version 1.0.0","title":"Program control flow graph extractor"},{"location":"analysis_modules/cfg/cfg_extractor/#control-flow-graph-extractors","text":"","title":"Control flow graph extractors"},{"location":"analysis_modules/cfg/cfg_extractor/#cfg-extractor-with-antlr-listener-version-1","text":"ANTLR listener to build control flow graph (CFG) for C++ functions If a CPP file contains multiple function the CFG is created for each function. For each function in the source file the CFG is stored in a dot file which can be visualized with graphviz.","title":"CFG Extractor with ANTLR listener (version 1)"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener1--changelog","text":"","title":"Changelog:"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener1--version-020","text":"Add writing the extracted CFG in dot file. Add visualization with pydot and graphviz","title":"Version 0.2.0"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener1--version-010","text":"","title":"Version 0.1.0"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener1.CFGInstListener","text":"","title":"CFGInstListener"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener1.CFGInstListener.__init__","text":":param common_token_stream: Source code in coda\\analysis\\cfg\\cfg_extractor_listener1.py def __init__ ( self , common_token_stream : CommonTokenStream , number_of_tokens , directory_name ): \"\"\" :param common_token_stream: \"\"\" self . cfg_path = 'CFGS/' + directory_name + '/' self . instrument_path = 'Instrument/' + directory_name + '/' self . block_dict = {} self . block_number = 0 self . block_start = 0 self . block_stop = 0 self . domain_name = 0 self . function_dict = {} self . select_junction_stack = [] self . select_decision_stack = [] self . iterate_junction_stack = [] self . iterate_stack = [] self . switch_junction_stack = [] self . switch_stack = [] self . switch_for_stack = [] self . has_jump_stack = [] self . has_default_stack = [] self . has_case_stack = [] self . try_stack = [] self . try_junction_stack = [] self . is_catch = False self . afterInsert = [ '' ] * number_of_tokens self . initial_nodes = set () self . final_nodes = set () self . label_dict = {} self . goto_dict = {} # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter . TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' )","title":"__init__()"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener1.CFGInstListener.enterStatement","text":"DFS traversal of a statement subtree, rooted at ctx. If the statement is a branching condition insert a prob. :param ctx: :return: Source code in coda\\analysis\\cfg\\cfg_extractor_listener1.py def enterStatement ( self , ctx : CPP14_v2Parser . StatementContext ): \"\"\" DFS traversal of a statement subtree, rooted at ctx. If the statement is a branching condition insert a prob. :param ctx: :return: \"\"\" # do-while and range-for if isinstance ( ctx . parentCtx , ( CPP14_v2Parser . Iterationstatement4Context , CPP14_v2Parser . Iterationstatement2Context )): # if there is a compound statement after the branchning condition: body = ctx . compoundstatement () if body is not None : self . insertAfter ( body ) # if there is only one statement after the branchning condition then create a block. else : new_code = '{' new_code += ' \\n ' + self . logLine () + '; \\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) # one line while and for elif isinstance ( ctx . parentCtx , CPP14_v2Parser . IterationstatementContext ): self . block_number += 1 self . block_start = ctx . start . line # if there is a compound statement after the branchning condition: body = ctx . compoundstatement () if body is not None : self . insertAfter ( body ) # if there is only one statement after the branchning condition then create a block. else : new_code = '{' new_code += ' \\n ' + self . logLine () + '; \\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) elif isinstance ( ctx . parentCtx , ( CPP14_v2Parser . Selectionstatement1Context , CPP14_v2Parser . Selectionstatement2Context )): self . block_number += 1 self . addDecisionEdge () self . block_start = ctx . start . line self . has_jump_stack . append ( False ) # if there is a compound statement after the branchning condition: body = ctx . compoundstatement () if body is not None : self . insertAfter ( body ) # if there is only one statement after the branchning condition then create a block. else : new_code = '{' new_code += ' \\n ' + self . logLine () + '; \\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) elif isinstance ( ctx . parentCtx , CPP14_v2Parser . Selectionstatement3Context ): if ctx . compoundstatement () is None : new_code = '{ \\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code )","title":"enterStatement()"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener1.CFGInstListener.enterTranslationunit","text":"Creating and open a text file for logging the instrumentation result :param ctx: :return: Source code in coda\\analysis\\cfg\\cfg_extractor_listener1.py def enterTranslationunit ( self , ctx : CPP14_v2Parser . TranslationunitContext ): \"\"\" Creating and open a text file for logging the instrumentation result :param ctx: :return: \"\"\" self . instrumented_source = open ( self . instrument_path + 'instrumented_source.cpp' , 'w' ) log_path = self . instrument_path + \"log_file.txt\" new_code = ' \\n #include <fstream> \\n std::ofstream logFile(\"log_file.txt\"); \\n\\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) self . domain_name = 0","title":"enterTranslationunit()"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener1.CFGInstListener.exitFunctionbody1","text":"Insert a prob at the end of the function only if the function is void. :param ctx: :return: Source code in coda\\analysis\\cfg\\cfg_extractor_listener1.py def exitFunctionbody1 ( self , ctx : CPP14_v2Parser . Functionbody1Context ): \"\"\" Insert a prob at the end of the function only if the function is void. :param ctx: :return: \"\"\" if not self . has_jump_stack . pop (): self . block_stop = ctx . stop . line self . addNode () self . final_nodes . add ( self . block_number )","title":"exitFunctionbody1()"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener1.CFGInstListener.exitTranslationunit","text":"Creating and open a text file for logging the instrumentation result :param ctx: :return: Source code in coda\\analysis\\cfg\\cfg_extractor_listener1.py def exitTranslationunit ( self , ctx : CPP14_v2Parser . TranslationunitContext ): \"\"\" Creating and open a text file for logging the instrumentation result :param ctx: :return: \"\"\" for i in range ( len ( self . afterInsert )): if self . afterInsert [ i ] != '' : self . token_stream_rewriter . insertAfter ( i , self . afterInsert [ i ]) self . instrumented_source . write ( self . token_stream_rewriter . getDefaultText ()) self . instrumented_source . close () functions_json = open ( self . cfg_path + 'functions.json' , 'w' ) json . dump ( self . function_dict , functions_json )","title":"exitTranslationunit()"},{"location":"analysis_modules/cfg/cfg_extractor/#cfg-extractor-with-antlr-listener-version-2","text":"ANTLR listener to build control flow graph (CFG) for C++ functions The improved version of the cfg_extractor_listener1.py module","title":"CFG Extractor with ANTLR listener (version 2)"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener2--changelog","text":"","title":"Changelog:"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener2--version-201","text":"Refactor the module","title":"version 2.0.1"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener2--version-200","text":"","title":"version 2.0.0"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener2.CFGInstListener","text":"","title":"CFGInstListener"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener2.CFGInstListener.__init__","text":":param common_token_stream: Source code in coda\\analysis\\cfg\\cfg_extractor_listener2.py def __init__ ( self , common_token_stream : CommonTokenStream , number_of_tokens , directory_name ): \"\"\" :param common_token_stream: \"\"\" self . cfg_path = 'extracted_cfgs/' + directory_name + '/' self . instrument_path = 'instrumented_programs/' + directory_name + '/' self . block_dict = {} self . block_number = 0 self . block_start = 0 self . block_stop = 0 self . domain_name = 0 self . function_dict = {} self . select_junction_stack = [] self . select_decision_stack = [] self . iterate_junction_stack = [] self . iterate_stack = [] self . switch_junction_stack = [] self . temp = [] self . switch_stack = [] self . switch_for_stack = [] self . has_jump_stack = [] self . is_for = [] self . is_while = [] self . is_doWhile = [] self . has_default_stack = [] self . has_case_stack = [] self . try_stack = [] self . try_junction_stack = [] self . is_catch = False self . throw_stack = [] self . afterInsert = [ '' ] * number_of_tokens self . initial_nodes = set () self . final_nodes = set () self . label_dict = {} self . goto_dict = {} # Move all the tokens in the source code in a buffer, token_stream_rewriter. if common_token_stream is not None : self . token_stream_rewriter = TokenStreamRewriter . TokenStreamRewriter ( common_token_stream ) else : raise TypeError ( 'common_token_stream is None' ) # create graph self . CFG_graph = nx . Graph ()","title":"__init__()"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener2.CFGInstListener.enterStatement","text":"DFS traversal of a statement subtree, rooted at ctx. If the statement is a branching condition insert a prob. :param ctx: :return: Source code in coda\\analysis\\cfg\\cfg_extractor_listener2.py def enterStatement ( self , ctx : CPP14_v2Parser . StatementContext ): \"\"\" DFS traversal of a statement subtree, rooted at ctx. If the statement is a branching condition insert a prob. :param ctx: :return: \"\"\" # do-while and range-for # line 342(CPP14_v2Parser.Iterationstatement4Context) if isinstance ( ctx . parentCtx , ( CPP14_v2Parser . Iterationstatement2Context )): # if there is a compound statement after the branchning condition: body = ctx . compoundstatement () if body != None : self . insertAfter ( body ) # if there is only one statement after the branchning condition then create a block. else : new_code = '{' new_code += ' \\n ' + self . logLine () + '; \\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) # one line while and for elif isinstance ( ctx . parentCtx , CPP14_v2Parser . IterationstatementContext ): self . block_number += 1 self . block_start = ctx . start . line # if there is a compound statement after the branchning condition: body = ctx . compoundstatement () if body != None : self . insertAfter ( body ) # if there is only one statement after the branchning condition then create a block. else : new_code = '{' new_code += ' \\n ' + self . logLine () + '; \\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) elif isinstance ( ctx . parentCtx , ( CPP14_v2Parser . Selectionstatement1Context , CPP14_v2Parser . Selectionstatement2Context )): self . block_number += 1 self . addDecisionEdge () self . block_start = ctx . start . line self . has_jump_stack . append ( False ) # if there is a compound statement after the branchning condition: body = ctx . compoundstatement () if body != None : self . insertAfter ( body ) # if there is only one statement after the branchning condition then create a block. else : new_code = '{' new_code += ' \\n ' + self . logLine () + '; \\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) elif isinstance ( ctx . parentCtx , CPP14_v2Parser . Selectionstatement3Context ): if ctx . compoundstatement () == None : new_code = '{ \\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code )","title":"enterStatement()"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener2.CFGInstListener.enterTranslationunit","text":"Creating and open a text file for logging the instrumentation result :param ctx: :return: Source code in coda\\analysis\\cfg\\cfg_extractor_listener2.py def enterTranslationunit ( self , ctx : CPP14_v2Parser . TranslationunitContext ): \"\"\" Creating and open a text file for logging the instrumentation result :param ctx: :return: \"\"\" self . instrumented_source = open ( self . instrument_path + 'instrumented_source.cpp' , 'w' ) log_path = self . instrument_path + \"log_file.txt\" new_code = ' \\n //in the name of allah \\n #include <fstream> \\n std::ofstream logFile(\"log_file.txt\"); \\n\\n ' self . token_stream_rewriter . insertBeforeIndex ( ctx . start . tokenIndex , new_code ) self . domain_name = 0","title":"enterTranslationunit()"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener2.CFGInstListener.exitFunctionbody1","text":"Insert a prob at the end of the function only if the function is void. :param ctx: :return: Source code in coda\\analysis\\cfg\\cfg_extractor_listener2.py def exitFunctionbody1 ( self , ctx : CPP14_v2Parser . Functionbody1Context ): \"\"\" Insert a prob at the end of the function only if the function is void. :param ctx: :return: \"\"\" if not self . has_jump_stack . pop (): self . block_stop = ctx . stop . line self . addNode () self . final_nodes . add ( self . block_number )","title":"exitFunctionbody1()"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_listener2.CFGInstListener.exitTranslationunit","text":"Creating and open a text file for logging the instrumentation result :param ctx: :return: Source code in coda\\analysis\\cfg\\cfg_extractor_listener2.py def exitTranslationunit ( self , ctx : CPP14_v2Parser . TranslationunitContext ): \"\"\" Creating and open a text file for logging the instrumentation result :param ctx: :return: \"\"\" for i in range ( len ( self . afterInsert )): if self . afterInsert [ i ] != '' : self . token_stream_rewriter . insertAfter ( i , self . afterInsert [ i ]) self . instrumented_source . write ( self . token_stream_rewriter . getDefaultText ()) self . instrumented_source . close () functions_json = open ( self . cfg_path + 'functions.json' , 'w' ) json . dump ( self . function_dict , functions_json )","title":"exitTranslationunit()"},{"location":"analysis_modules/cfg/cfg_extractor/#cfg-extractor-with-antlr-visitor","text":"ANTLR visitor to build control flow graph (CFG) for C++ functions The improved version of the cfg_extractor_listener1.py module","title":"CFG Extractor with ANTLR visitor"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_visitor--changelog","text":"","title":"Changelog:"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_visitor--version-101","text":"Refactor the module","title":"version 1.0.1"},{"location":"analysis_modules/cfg/cfg_extractor/#coda.analysis.cfg.cfg_extractor_visitor--version-100","text":"","title":"version 1.0.0"},{"location":"analysis_modules/paths/prime_path_extractor/","text":"Prime-path extractor The Graph class in the module computes prime paths ControlFlowGraph __init__ ( self , graph_file ) special Arges: graph_file (str): The path of saved CFG graph Source code in coda\\analysis\\paths\\prime_path_extractor.py def __init__ ( self , graph_file ): \"\"\" Arges: graph_file (str): The path of saved CFG graph \"\"\" lines = graph_file . readlines () self . edges = {} self . nodes = set () self . inits = set () self . finals = set () for i in range ( len ( lines ) - 2 ): line = lines [ i ] n , dest = ( int ( x ) for x in line . split ( ' ' )) self . nodes . add ( dest ) try : self . edges [ n ] . append ( dest ) except : self . edges [ n ] = [ dest ] init_line = lines [ - 2 ] init_nodes = set ( int ( x ) for x in init_line . split ( ':' )[ 1 ] . split ( ' ' )) self . inits = init_nodes self . nodes . update ( self . inits ) final_line = lines [ - 1 ] final_nodes = set ( int ( x ) for x in final_line . split ( ':' )[ 1 ] . split ( ' ' )) self . finals = final_nodes self . nodes . update ( self . finals ) computePrimePaths ( self ) Source code in coda\\analysis\\paths\\prime_path_extractor.py def computePrimePaths ( self ): \"\"\" \"\"\" self . primePaths = [] try_paths = [[ n ] for n in self . nodes ] while len ( try_paths ) > 0 : new_try_paths = [] for path in try_paths : if path [ 0 ] == path [ - 1 ] and len ( path ) >= 2 : # prime path self . primePaths . append ( path ) elif self . reachEnd ( path ): if self . reachHead ( path ): # prime path self . primePaths . append ( path ) else : # extendable path new_try_paths += self . extend ( path ) try_paths = new_try_paths extend ( self , path ) Source code in coda\\analysis\\paths\\prime_path_extractor.py def extend ( self , path ): \"\"\" \"\"\" extended_paths = [] last = path [ - 1 ] if last in self . finals : return list () for n in self . edges [ last ]: if n not in path [ 1 :]: extended_paths += [ path + [ n ]] return extended_paths reachEnd ( self , path ) Source code in coda\\analysis\\paths\\prime_path_extractor.py def reachEnd ( self , path ): \"\"\" \"\"\" last = path [ - 1 ] if last in self . finals : return True for n in self . edges [ last ]: if n not in path [ 1 :]: return False return True reachHead ( self , path ) Source code in coda\\analysis\\paths\\prime_path_extractor.py def reachHead ( self , path ): \"\"\" \"\"\" first = path [ 0 ] non_final_nodes = self . nodes - self . finals for n in non_final_nodes : if first in self . edges [ n ] and n not in path : return False return True","title":"Program prime paths extractor"},{"location":"analysis_modules/paths/prime_path_extractor/#prime-path-extractor","text":"The Graph class in the module computes prime paths","title":"Prime-path extractor"},{"location":"analysis_modules/paths/prime_path_extractor/#coda.analysis.paths.prime_path_extractor.ControlFlowGraph","text":"","title":"ControlFlowGraph"},{"location":"analysis_modules/paths/prime_path_extractor/#coda.analysis.paths.prime_path_extractor.ControlFlowGraph.__init__","text":"Arges: graph_file (str): The path of saved CFG graph Source code in coda\\analysis\\paths\\prime_path_extractor.py def __init__ ( self , graph_file ): \"\"\" Arges: graph_file (str): The path of saved CFG graph \"\"\" lines = graph_file . readlines () self . edges = {} self . nodes = set () self . inits = set () self . finals = set () for i in range ( len ( lines ) - 2 ): line = lines [ i ] n , dest = ( int ( x ) for x in line . split ( ' ' )) self . nodes . add ( dest ) try : self . edges [ n ] . append ( dest ) except : self . edges [ n ] = [ dest ] init_line = lines [ - 2 ] init_nodes = set ( int ( x ) for x in init_line . split ( ':' )[ 1 ] . split ( ' ' )) self . inits = init_nodes self . nodes . update ( self . inits ) final_line = lines [ - 1 ] final_nodes = set ( int ( x ) for x in final_line . split ( ':' )[ 1 ] . split ( ' ' )) self . finals = final_nodes self . nodes . update ( self . finals )","title":"__init__()"},{"location":"analysis_modules/paths/prime_path_extractor/#coda.analysis.paths.prime_path_extractor.ControlFlowGraph.computePrimePaths","text":"Source code in coda\\analysis\\paths\\prime_path_extractor.py def computePrimePaths ( self ): \"\"\" \"\"\" self . primePaths = [] try_paths = [[ n ] for n in self . nodes ] while len ( try_paths ) > 0 : new_try_paths = [] for path in try_paths : if path [ 0 ] == path [ - 1 ] and len ( path ) >= 2 : # prime path self . primePaths . append ( path ) elif self . reachEnd ( path ): if self . reachHead ( path ): # prime path self . primePaths . append ( path ) else : # extendable path new_try_paths += self . extend ( path ) try_paths = new_try_paths","title":"computePrimePaths()"},{"location":"analysis_modules/paths/prime_path_extractor/#coda.analysis.paths.prime_path_extractor.ControlFlowGraph.extend","text":"Source code in coda\\analysis\\paths\\prime_path_extractor.py def extend ( self , path ): \"\"\" \"\"\" extended_paths = [] last = path [ - 1 ] if last in self . finals : return list () for n in self . edges [ last ]: if n not in path [ 1 :]: extended_paths += [ path + [ n ]] return extended_paths","title":"extend()"},{"location":"analysis_modules/paths/prime_path_extractor/#coda.analysis.paths.prime_path_extractor.ControlFlowGraph.reachEnd","text":"Source code in coda\\analysis\\paths\\prime_path_extractor.py def reachEnd ( self , path ): \"\"\" \"\"\" last = path [ - 1 ] if last in self . finals : return True for n in self . edges [ last ]: if n not in path [ 1 :]: return False return True","title":"reachEnd()"},{"location":"analysis_modules/paths/prime_path_extractor/#coda.analysis.paths.prime_path_extractor.ControlFlowGraph.reachHead","text":"Source code in coda\\analysis\\paths\\prime_path_extractor.py def reachHead ( self , path ): \"\"\" \"\"\" first = path [ 0 ] non_final_nodes = self . nodes - self . finals for n in non_final_nodes : if first in self . edges [ n ] and n not in path : return False return True","title":"reachHead()"},{"location":"proposals/core_program_analysis_development/","text":"Core program analysis development Coming soon.","title":"Core program analysis development"},{"location":"proposals/core_program_analysis_development/#core-program-analysis-development","text":"Coming soon.","title":"Core program analysis development"},{"location":"tutorials/antlr_basics/","text":"ANTLR basics Please refer to the ANTLR basics tutorials in our supplementary project, CodART .","title":"ANTLR basics"},{"location":"tutorials/antlr_basics/#antlr-basics","text":"Please refer to the ANTLR basics tutorials in our supplementary project, CodART .","title":"ANTLR basics"},{"location":"tutorials/metrics_computation/","text":"Source code metrics computation By: Morteza Zakeri Last update: May 02, 2022 Edition 2 Source code metrics are extracted from the source code of the software, and their values allow us to reach conclusions about the quality attributes measured by the metrics. A practical approach to computing such metrics is static program source code analysis. Again this analysis can be performed by using the compiler front-end to deal with the parse tree and symbol table. The idea is to create a symbol table for the program under analysis and extract desired metrics. In this section, we demonstrate the use of ANLTR to compute two essential design metrics, FANIN, and FANOUT, which affect the testability of a module. FANIN and FANOUT can be computed from UML class diagrams. In the case of source code, we require to extract the class diagram from the program source code. We begin with constructing a simple symbol table to hold the necessary entities, e.g., classes and their relationships. Similar to our source code instrumentation tutorial , the ANTLR listener mechanism is utilized to build the symbol table. The structure of our symbol table is shown in Figure 1. Figure 1: Class diagram of a simple symbol table for C++ The class diagram in Figure 1 has been implemented in Python. During syntax tree walking, each entity is recognized and saved in the corresponding instance of symbol table entities. For example, whenever a method is recognized, the instance of the Method class will be created to hold this method. The Model class is needed to keep a list of recognized classes as the top-level entities. The implementation code of the proposed symbol table in Python is straightforward, and we omit the code here. The next step is creating a listener and adding codes to fill the symbol table. Listing 1 shows the listener used to recognize and add source code classes to the symbol table. class DefinitionPassListener(CPP14Listener): \"\"\" Pass 1: Extracting the classes and structs from a given CPP source code \"\"\" def __init__(self, model: Model = None): if model is None: self.model = Model() else: self.model = model self.class_instance = None def enterClassspecifier(self, ctx: CPP14Parser.ClassspecifierContext): if self.class_instance is None: self.class_instance = Class() def exitClassspecifier(self, ctx: CPP14Parser.ClassspecifierContext): if self.class_instance is not None: self.model.class_list.append(self.class_instance) self.class_instance = None def enterClassheadname(self, ctx: CPP14Parser.ClassheadnameContext): if self.class_instance is not None: self.class_instance.name = ctx.getText() Listing 1: Recognizing classes in source code and inserting them into the symbol table When an instance of DefinitionPassListner in Listing 1 is passed to the ParseTreeWalker instance, the classes within the source code are identified and inserted into the symbol table. This task has been performed only by implementing the listener methods, which correspond to the class definition rule in C++ grammar. To better understand which methods of the base listener ( CPP14Listener ), generated by ANTLR, should be implemented to perform this task, we may look at the parse tree of the simple program, including one class with one field, as shown in Listing 2. class A{ string name; }; Listing 2: C++ code snip with one class and one field. The parse tree of code snip in Listing is shown in Figure 2. The parse tree visualization can be performed by the ANTLR plugin for IntelliJ IDEA . One can see the complexity of the C++ language and its compilation. The pares tree for the program with only four lines of codes has 39 nodes and more than 350 parse decisions (invocation in the recursive descent parsing), which shows that the real programming languages are too complex. Therefore, the only way to analyze and test them is to utilize compiler techniques. Figure 2: The parse tree for the code snippet shown in Listing 2 The recognized classes, by applying DefinitionPassListner , only have a name (set in Line 25). The DefinitionPassListner listener class does not capture any required relationships for computing FANIN and FANOUT or any other analysis. Relationships between classes in each program occurred in different ways, e.g., through the aggregation. In aggregation, one class has a field with the type of the other class. To extract the aggregation relationship, we should extract all fields whose types are user-defined. Therefore, we create another listener with the following codes: class ResolvePassListener(DefinitionPassListener): \"\"\" Pass 2: Extracting the classes' fields \"\"\" def __init__(self, model: Model = None): super(DefinitionPassListener, self).__init__(model=model) self.enter_member_specification = False self.field = Field() def enterMemberspecification(self, ctx: CPP14Parser.MemberspecificationContext): if ctx.getChildCount() == 3: self.enter_member_specification = True def enterDeclspecifier(self, ctx: CPP14Parser.DeclspecifierContext): if self.enter_member_specification: ctx_the_type_name = ctx.getText() for class_instance in self.model.class_list: if ctx_the_type_name == class_instance.name: self.field.type = class_instance self.class_instance.fields.append(field) break Listing 3: Adding class fields to the program symbol table The method enterDeclspecifier is invoked by ParseTreeWalker each time a field is defined in the program source code. In ResolvePassListener an extra check is required to ensure that the recognized variable belongs to the class or not. The flag enter_member_specification is set to true in enterMemeberspecification method and used to understand the scope of the variable. In enterDeclspecifier method, the name of the variable is checked to find whether it is the name of another class or not. Indeed, if the field has a user-defined type, then the type of this field is resolved and added to the current class fields. There are some practical considerations at this point. Why has a separate class defined for resolving the fields of classes? The ResolvePassListener has inherited from DefinitionPassListner , but why? The reason for separating the listener code into two classes is that the symbol table can not be completed by traversing the parse tree only once. If we try to add the field of the class at the same time that we are adding the class itself, we may not be able to find the proper type of the user-defined fields since all types still have not been inserted into the symbol table. The best practice is that two separate analysis passes are applied. One for adding types to the symbol table called definition pass, and another one for resolving the types to check or complete their information called resolved pass. Each pass in the compiling process reads the source code from start to end. The resolve pass inherits from the definition pass since the operation in the definition pass is still required. For example, Line 20 in ResolvePassListener requires the current class when adding the recognized field to it. DefinitionPassListner , in Listing 1, is not suitable to use as a parent for ResolvePassListener. It only inserts new classes to the symbol table; however, we need to retrieve them when the ResolvePassListener is being applied. Another problem is that if the current code for DefinitionPassListner is executed more than once, the same class is inserted to self.model.class_list the object in the symbol table. We should fix the class DefinitionPassListner to solve these two problems. First, before adding a new class (Line 25 in Listing 1), it should be checked that class has not existed in the symbol table. Second, if the class already exists in the code, in enterClassheadname method, the corresponding class should be retrieved by its name and assigned to self.class_instance object. These conditions are expected to be met when the ResolvePassListener is executed as a second pass of our analysis. Listing 4 shows the modified version of the DefinitionPassListner . class DefinitionPassListener(CPP14Listener): \"\"\" Pass 1 (modified): Extracting the classes and structs \"\"\" def __init__(self, model: Model = None): if model is None: self.model = Model() else: self.model = model self.class_instance = None def enterClassspecifier(self, ctx: CPP14Parser.ClassspecifierContext): if self.class_instance is None: self.class_instance = Class() def exitClassspecifier(self, ctx: CPP14Parser.ClassspecifierContext): if self.class_instance is not None: if self.model.find_calss_by_name(self.class_instance) == False: self.model.class_list.append(self.class_instance) self.class_instance = None def enterClassheadname(self, ctx: CPP14Parser.ClassheadnameContext): if self.class_instance is not None: if self.model.find_calss_by_name(ctx.getText()): self.class_instance = self.medel.get_class_by_name(class_instance.name) else: self.class_instance.name = ctx.getText() Listing 4: The fixed version of the DefinitionPassListener class. In this tutorial, we assumed that the input program is compilable, and hence we did not perform additional compile-time tasks such as type checking. The complete implementation of two listeners, including import statements and some additional codes, will be available on the CodA repository . Once our listeners are completed, we can add a driver code to attach these listeners to a ParseTreeWalker and perform the target task, as discussed in the ANTLR basic tutorial . The only difference is that we have two listeners that must be executed in order to get the desired result. Listing 5 shows the driver code for our static analysis task. stream = FileStream(input_string) lexer = test_v2Lexer(stream) token_stream = CommonTokenStream(lexer) parser = test_v2Parser(token_stream) parse_tree = parser.start() pass1 = DefinitionPassListener() walker = ParseTreeWalker() walker.walk(listener=pass1, t=parse_tree) pass2 = ResolvePassListener(model=pass1.model) walker.walk.walk(listener=pass2, t=parse_tree) Listing 5: Driver coed to perform static analysis of the source code. The last step in our analysis is to build the class diagram as a directed annotated graph forming the symbol table and compute the FAN-IN and FAN-OUT metrics for each class. This step is done by creating a node for each class and adding an edge between two classes, which have an aggregate relationship together. The direction of each edge specifies the direction of aggregation. Listing 6 shows the methods that create and visualize the discussed graph. Two methods are defined in the Model class, which was part of our symbol table in previous steps. The first method, create_graph , creates a graph for a class diagram. It uses the NetworkX library to work with graphs. The second method, draw_graph , makes visualization of the created graph. The Model class also has two fields class_list and class_diagram , which have not been shown in Listing 6. The first field holds all class instances of the source code, and the second field holds the class diagram corresponding graph. __date__ = '2021-07-19' __author__ = 'Morteza Zakeri' def create_graph(self): class_diagram = nx.DiGraph() for class_instance in self.class_list: class_diagram.add_node(class_instance.name) for class_instance in self.class_list: if class_instance.attributes_list is not None: for class_attribute in class_instance.attributes_list: if isinstance(class_attribute.variable_type, Class) or isinstance(class_attribute.variable_type, Structure): w = 1 if class_diagram.has_edge(class_instance.name, class_attribute.variable_type.name): w = class_diagram[class_instance.name][class_attribute.variable_type.name]['weight'] w += 1 class_diagram.add_edge(class_instance.name, class_attribute.variable_type.name, rel='Aggregation', weight=w) self.class_diagram = class_diagram def draw_graph(self): new_names_dict = dict() for node_name in self.class_diagram.nodes: new_names_dict.update({node_name: node_name}) edge_labels = nx.get_edge_attributes(self.class_diagram, 'rel') edge_labels2 = nx.get_edge_attributes(self.class_diagram, 'cardinality') pos = nx.kamada_kawai_layout(self.class_diagram) nx.draw_networkx_nodes(self.class_diagram, pos, nodelist=self.class_diagram.nodes, node_shape='s', node_size=1000, alpha=0.25, node_color='r') nx.draw_networkx_edges(self.class_diagram, pos, edgelist=list(self.class_diagram.edges), width=2.0, alpha=0.95, edge_color='b') nx.draw_networkx_edge_labels(self.class_diagram, pos, labels=edge_labels) nx.draw_networkx_edge_labels(self.class_diagram, pos, labels=edge_labels2) nx.draw_networkx_labels(self.class_diagram, pos, new_names_dict, font_size=11) plt.show() Listing 6: Methods for creating and visualizing a simple class diagram. FAN-IN and FAN-OUT can for each class are defined respectively as in-degree and out-degree of the class diagram corresponding graph. Therefore, having that graph means that we can compute these metrics quickly. To illustrate the discussed static analysis on a real program, consider the C++ program in Listing 7, which has four simple classes: Person , Student , Teacher , and Course . The implementation of classes has been omitted for simplicity. Both the Student class and Teacher class have been inherited from the class Person . In addition, the Student class has aggregated an instance of the Course class. # include <string> # include <iostream> using namespace std; class Person { protected: string firstName; string lastName; int nationalCode; public: Person(string firstName, string lastName, int nationalCode); void setPersonName(string firstName, string lastName); virtual int doJob(); }; Person::Person(string firstName, string lastName, int nationalCode) { this->firstName = firstName; this->lastName = lastName; this->nationalCode = nationalCode; } void Person::setPersonName(string firstName, string lastName) { this->firstName = firstName; this->lastName = lastName; } int Person::doJob() { cout << this->firstName << \" is a person \" << endl; return 0; } class Student: public Person { private: long studentNumber; Course* cource; public: Student(string firstName, string lastName, int nationalCode, long studentNumber); int doJob() override; }; Student::Student(string firstName, string lastName, int nationalCode, long studentNumber):Person(firstName, lastName, nationalCode) { this->studentNumber = studentNumber; cout << \"I am a student: \" << this->studentNumber << endl; this->cource = new Course(); this->cource->name = \"Software Engieering\"; } int Student::doJob() { cout << this->firstName << \" is studing \" << endl; return 20; } class Teacher: public Person { private: long teacherNumber; public: Teacher(string firstName, string lastName, int nationalCode, long teacherNumber); int doJob() override; }; Teacher::Teacher(string firstName, string lastName, int nationalCode, long teacherNumber):Person(firstName, lastName, nationalCode) { this->teacherNumber = teacherNumber; cout << \"I am a teacher: \" << this->teacherNumber << endl; } int Teacher::doJob() { cout << this->firstName << \" is teaching \" << endl; return 0; } class Course { public: string name; int number; Course(string course_name, int course_numbber = 0); }; Course::Course(string course_name, int course_numbber) { this->name = course_name; this->number = course_numbber; } /* main function */ int main() { Teacher t1(\"Saeed\", \"Parsa\", 1234, 1398); Student s1(\"Morteza\", \"Zakeri\", 5678, 2020); t1.doJob(); s1.doJob(); } Listing 7: A C++ application to test the developed static analysis program in this tutorial. The corresponding graph for the class diagram of this program, which is the output of executing codes in Listings 5 and 6, has been shown in Figure 3. As one can see, the inheritance relationships also have been shown in the figure. We omitted the code that captures the inheritance relationship in this section. You may ask to implement the extraction of inheritance relationships after reading this tutorial. Figure 3: Class diagram for the program shown in Listing 7. FAN-IN and FAN-OUT metrics can be computed, as discussed earlier. For this simple example, FAN-IN for class Student is 0, and FAN-OUT is one; however, for complete computation of these metrics, all relationships, including association, dependencies, and parameters passing, should be considered. Summary In this tutorial and the previous one , I discussed the application of compilers in static and dynamic software analysis. I demonstrated these applications through a simple example of source code instrumentation and metrics computation. The former is a transformation task that modifies the source code, and the latter is an analysis task that extracts some information from the source code. Both of them are essential tasks in the future of software engineering. Systematic software testing and quality assurance tools can be built on top of compiler tools such as ANTLR, LLVM, JDT, and Roslyn, with techniques presented in this chapter. Compilers build a detailed model of application code as they validate the syntax and semantics of that code. While traditional compilers used such a model to build the executable output from the source code in a block box manner, the new generation of compilers provides APIs to access the internal details of this model, which can be utilized to build more reliable software. Software testing is more realistic with advanced support by compilers.","title":"Source code metrics computation"},{"location":"tutorials/metrics_computation/#source-code-metrics-computation","text":"By: Morteza Zakeri Last update: May 02, 2022 Edition 2 Source code metrics are extracted from the source code of the software, and their values allow us to reach conclusions about the quality attributes measured by the metrics. A practical approach to computing such metrics is static program source code analysis. Again this analysis can be performed by using the compiler front-end to deal with the parse tree and symbol table. The idea is to create a symbol table for the program under analysis and extract desired metrics. In this section, we demonstrate the use of ANLTR to compute two essential design metrics, FANIN, and FANOUT, which affect the testability of a module. FANIN and FANOUT can be computed from UML class diagrams. In the case of source code, we require to extract the class diagram from the program source code. We begin with constructing a simple symbol table to hold the necessary entities, e.g., classes and their relationships. Similar to our source code instrumentation tutorial , the ANTLR listener mechanism is utilized to build the symbol table. The structure of our symbol table is shown in Figure 1. Figure 1: Class diagram of a simple symbol table for C++ The class diagram in Figure 1 has been implemented in Python. During syntax tree walking, each entity is recognized and saved in the corresponding instance of symbol table entities. For example, whenever a method is recognized, the instance of the Method class will be created to hold this method. The Model class is needed to keep a list of recognized classes as the top-level entities. The implementation code of the proposed symbol table in Python is straightforward, and we omit the code here. The next step is creating a listener and adding codes to fill the symbol table. Listing 1 shows the listener used to recognize and add source code classes to the symbol table. class DefinitionPassListener(CPP14Listener): \"\"\" Pass 1: Extracting the classes and structs from a given CPP source code \"\"\" def __init__(self, model: Model = None): if model is None: self.model = Model() else: self.model = model self.class_instance = None def enterClassspecifier(self, ctx: CPP14Parser.ClassspecifierContext): if self.class_instance is None: self.class_instance = Class() def exitClassspecifier(self, ctx: CPP14Parser.ClassspecifierContext): if self.class_instance is not None: self.model.class_list.append(self.class_instance) self.class_instance = None def enterClassheadname(self, ctx: CPP14Parser.ClassheadnameContext): if self.class_instance is not None: self.class_instance.name = ctx.getText() Listing 1: Recognizing classes in source code and inserting them into the symbol table When an instance of DefinitionPassListner in Listing 1 is passed to the ParseTreeWalker instance, the classes within the source code are identified and inserted into the symbol table. This task has been performed only by implementing the listener methods, which correspond to the class definition rule in C++ grammar. To better understand which methods of the base listener ( CPP14Listener ), generated by ANTLR, should be implemented to perform this task, we may look at the parse tree of the simple program, including one class with one field, as shown in Listing 2. class A{ string name; }; Listing 2: C++ code snip with one class and one field. The parse tree of code snip in Listing is shown in Figure 2. The parse tree visualization can be performed by the ANTLR plugin for IntelliJ IDEA . One can see the complexity of the C++ language and its compilation. The pares tree for the program with only four lines of codes has 39 nodes and more than 350 parse decisions (invocation in the recursive descent parsing), which shows that the real programming languages are too complex. Therefore, the only way to analyze and test them is to utilize compiler techniques. Figure 2: The parse tree for the code snippet shown in Listing 2 The recognized classes, by applying DefinitionPassListner , only have a name (set in Line 25). The DefinitionPassListner listener class does not capture any required relationships for computing FANIN and FANOUT or any other analysis. Relationships between classes in each program occurred in different ways, e.g., through the aggregation. In aggregation, one class has a field with the type of the other class. To extract the aggregation relationship, we should extract all fields whose types are user-defined. Therefore, we create another listener with the following codes: class ResolvePassListener(DefinitionPassListener): \"\"\" Pass 2: Extracting the classes' fields \"\"\" def __init__(self, model: Model = None): super(DefinitionPassListener, self).__init__(model=model) self.enter_member_specification = False self.field = Field() def enterMemberspecification(self, ctx: CPP14Parser.MemberspecificationContext): if ctx.getChildCount() == 3: self.enter_member_specification = True def enterDeclspecifier(self, ctx: CPP14Parser.DeclspecifierContext): if self.enter_member_specification: ctx_the_type_name = ctx.getText() for class_instance in self.model.class_list: if ctx_the_type_name == class_instance.name: self.field.type = class_instance self.class_instance.fields.append(field) break Listing 3: Adding class fields to the program symbol table The method enterDeclspecifier is invoked by ParseTreeWalker each time a field is defined in the program source code. In ResolvePassListener an extra check is required to ensure that the recognized variable belongs to the class or not. The flag enter_member_specification is set to true in enterMemeberspecification method and used to understand the scope of the variable. In enterDeclspecifier method, the name of the variable is checked to find whether it is the name of another class or not. Indeed, if the field has a user-defined type, then the type of this field is resolved and added to the current class fields. There are some practical considerations at this point. Why has a separate class defined for resolving the fields of classes? The ResolvePassListener has inherited from DefinitionPassListner , but why? The reason for separating the listener code into two classes is that the symbol table can not be completed by traversing the parse tree only once. If we try to add the field of the class at the same time that we are adding the class itself, we may not be able to find the proper type of the user-defined fields since all types still have not been inserted into the symbol table. The best practice is that two separate analysis passes are applied. One for adding types to the symbol table called definition pass, and another one for resolving the types to check or complete their information called resolved pass. Each pass in the compiling process reads the source code from start to end. The resolve pass inherits from the definition pass since the operation in the definition pass is still required. For example, Line 20 in ResolvePassListener requires the current class when adding the recognized field to it. DefinitionPassListner , in Listing 1, is not suitable to use as a parent for ResolvePassListener. It only inserts new classes to the symbol table; however, we need to retrieve them when the ResolvePassListener is being applied. Another problem is that if the current code for DefinitionPassListner is executed more than once, the same class is inserted to self.model.class_list the object in the symbol table. We should fix the class DefinitionPassListner to solve these two problems. First, before adding a new class (Line 25 in Listing 1), it should be checked that class has not existed in the symbol table. Second, if the class already exists in the code, in enterClassheadname method, the corresponding class should be retrieved by its name and assigned to self.class_instance object. These conditions are expected to be met when the ResolvePassListener is executed as a second pass of our analysis. Listing 4 shows the modified version of the DefinitionPassListner . class DefinitionPassListener(CPP14Listener): \"\"\" Pass 1 (modified): Extracting the classes and structs \"\"\" def __init__(self, model: Model = None): if model is None: self.model = Model() else: self.model = model self.class_instance = None def enterClassspecifier(self, ctx: CPP14Parser.ClassspecifierContext): if self.class_instance is None: self.class_instance = Class() def exitClassspecifier(self, ctx: CPP14Parser.ClassspecifierContext): if self.class_instance is not None: if self.model.find_calss_by_name(self.class_instance) == False: self.model.class_list.append(self.class_instance) self.class_instance = None def enterClassheadname(self, ctx: CPP14Parser.ClassheadnameContext): if self.class_instance is not None: if self.model.find_calss_by_name(ctx.getText()): self.class_instance = self.medel.get_class_by_name(class_instance.name) else: self.class_instance.name = ctx.getText() Listing 4: The fixed version of the DefinitionPassListener class. In this tutorial, we assumed that the input program is compilable, and hence we did not perform additional compile-time tasks such as type checking. The complete implementation of two listeners, including import statements and some additional codes, will be available on the CodA repository . Once our listeners are completed, we can add a driver code to attach these listeners to a ParseTreeWalker and perform the target task, as discussed in the ANTLR basic tutorial . The only difference is that we have two listeners that must be executed in order to get the desired result. Listing 5 shows the driver code for our static analysis task. stream = FileStream(input_string) lexer = test_v2Lexer(stream) token_stream = CommonTokenStream(lexer) parser = test_v2Parser(token_stream) parse_tree = parser.start() pass1 = DefinitionPassListener() walker = ParseTreeWalker() walker.walk(listener=pass1, t=parse_tree) pass2 = ResolvePassListener(model=pass1.model) walker.walk.walk(listener=pass2, t=parse_tree) Listing 5: Driver coed to perform static analysis of the source code. The last step in our analysis is to build the class diagram as a directed annotated graph forming the symbol table and compute the FAN-IN and FAN-OUT metrics for each class. This step is done by creating a node for each class and adding an edge between two classes, which have an aggregate relationship together. The direction of each edge specifies the direction of aggregation. Listing 6 shows the methods that create and visualize the discussed graph. Two methods are defined in the Model class, which was part of our symbol table in previous steps. The first method, create_graph , creates a graph for a class diagram. It uses the NetworkX library to work with graphs. The second method, draw_graph , makes visualization of the created graph. The Model class also has two fields class_list and class_diagram , which have not been shown in Listing 6. The first field holds all class instances of the source code, and the second field holds the class diagram corresponding graph. __date__ = '2021-07-19' __author__ = 'Morteza Zakeri' def create_graph(self): class_diagram = nx.DiGraph() for class_instance in self.class_list: class_diagram.add_node(class_instance.name) for class_instance in self.class_list: if class_instance.attributes_list is not None: for class_attribute in class_instance.attributes_list: if isinstance(class_attribute.variable_type, Class) or isinstance(class_attribute.variable_type, Structure): w = 1 if class_diagram.has_edge(class_instance.name, class_attribute.variable_type.name): w = class_diagram[class_instance.name][class_attribute.variable_type.name]['weight'] w += 1 class_diagram.add_edge(class_instance.name, class_attribute.variable_type.name, rel='Aggregation', weight=w) self.class_diagram = class_diagram def draw_graph(self): new_names_dict = dict() for node_name in self.class_diagram.nodes: new_names_dict.update({node_name: node_name}) edge_labels = nx.get_edge_attributes(self.class_diagram, 'rel') edge_labels2 = nx.get_edge_attributes(self.class_diagram, 'cardinality') pos = nx.kamada_kawai_layout(self.class_diagram) nx.draw_networkx_nodes(self.class_diagram, pos, nodelist=self.class_diagram.nodes, node_shape='s', node_size=1000, alpha=0.25, node_color='r') nx.draw_networkx_edges(self.class_diagram, pos, edgelist=list(self.class_diagram.edges), width=2.0, alpha=0.95, edge_color='b') nx.draw_networkx_edge_labels(self.class_diagram, pos, labels=edge_labels) nx.draw_networkx_edge_labels(self.class_diagram, pos, labels=edge_labels2) nx.draw_networkx_labels(self.class_diagram, pos, new_names_dict, font_size=11) plt.show() Listing 6: Methods for creating and visualizing a simple class diagram. FAN-IN and FAN-OUT can for each class are defined respectively as in-degree and out-degree of the class diagram corresponding graph. Therefore, having that graph means that we can compute these metrics quickly. To illustrate the discussed static analysis on a real program, consider the C++ program in Listing 7, which has four simple classes: Person , Student , Teacher , and Course . The implementation of classes has been omitted for simplicity. Both the Student class and Teacher class have been inherited from the class Person . In addition, the Student class has aggregated an instance of the Course class. # include <string> # include <iostream> using namespace std; class Person { protected: string firstName; string lastName; int nationalCode; public: Person(string firstName, string lastName, int nationalCode); void setPersonName(string firstName, string lastName); virtual int doJob(); }; Person::Person(string firstName, string lastName, int nationalCode) { this->firstName = firstName; this->lastName = lastName; this->nationalCode = nationalCode; } void Person::setPersonName(string firstName, string lastName) { this->firstName = firstName; this->lastName = lastName; } int Person::doJob() { cout << this->firstName << \" is a person \" << endl; return 0; } class Student: public Person { private: long studentNumber; Course* cource; public: Student(string firstName, string lastName, int nationalCode, long studentNumber); int doJob() override; }; Student::Student(string firstName, string lastName, int nationalCode, long studentNumber):Person(firstName, lastName, nationalCode) { this->studentNumber = studentNumber; cout << \"I am a student: \" << this->studentNumber << endl; this->cource = new Course(); this->cource->name = \"Software Engieering\"; } int Student::doJob() { cout << this->firstName << \" is studing \" << endl; return 20; } class Teacher: public Person { private: long teacherNumber; public: Teacher(string firstName, string lastName, int nationalCode, long teacherNumber); int doJob() override; }; Teacher::Teacher(string firstName, string lastName, int nationalCode, long teacherNumber):Person(firstName, lastName, nationalCode) { this->teacherNumber = teacherNumber; cout << \"I am a teacher: \" << this->teacherNumber << endl; } int Teacher::doJob() { cout << this->firstName << \" is teaching \" << endl; return 0; } class Course { public: string name; int number; Course(string course_name, int course_numbber = 0); }; Course::Course(string course_name, int course_numbber) { this->name = course_name; this->number = course_numbber; } /* main function */ int main() { Teacher t1(\"Saeed\", \"Parsa\", 1234, 1398); Student s1(\"Morteza\", \"Zakeri\", 5678, 2020); t1.doJob(); s1.doJob(); } Listing 7: A C++ application to test the developed static analysis program in this tutorial. The corresponding graph for the class diagram of this program, which is the output of executing codes in Listings 5 and 6, has been shown in Figure 3. As one can see, the inheritance relationships also have been shown in the figure. We omitted the code that captures the inheritance relationship in this section. You may ask to implement the extraction of inheritance relationships after reading this tutorial. Figure 3: Class diagram for the program shown in Listing 7. FAN-IN and FAN-OUT metrics can be computed, as discussed earlier. For this simple example, FAN-IN for class Student is 0, and FAN-OUT is one; however, for complete computation of these metrics, all relationships, including association, dependencies, and parameters passing, should be considered.","title":"Source code metrics computation"},{"location":"tutorials/metrics_computation/#summary","text":"In this tutorial and the previous one , I discussed the application of compilers in static and dynamic software analysis. I demonstrated these applications through a simple example of source code instrumentation and metrics computation. The former is a transformation task that modifies the source code, and the latter is an analysis task that extracts some information from the source code. Both of them are essential tasks in the future of software engineering. Systematic software testing and quality assurance tools can be built on top of compiler tools such as ANTLR, LLVM, JDT, and Roslyn, with techniques presented in this chapter. Compilers build a detailed model of application code as they validate the syntax and semantics of that code. While traditional compilers used such a model to build the executable output from the source code in a block box manner, the new generation of compilers provides APIs to access the internal details of this model, which can be utilized to build more reliable software. Software testing is more realistic with advanced support by compilers.","title":"Summary"},{"location":"tutorials/program_instrumentation/","text":"Program instrumentation By: Morteza Zakeri Last update: July 19, 2020 Edition 1 In this tutorial we describe a primary task in source code transformation, i.e. , program instrumentation, which is one of the CodA features. The task can be performed by properly applying compiler techniques, adding required code snippets at specific source code places. Instrumentation is the fundamental prerequisite for almost all dynamic analysis types. Let us begin with a simple case in which the purpose of instrumentation is to log the executed path of the program control flow graph for each execution. Consider the following C++ program used to calculate the greatest common divider (GCD) of two integers: #include <stdio.h> #include <iostream> int main() { int num1, num2, i, gcd; std::cout << \"Enter two integers: \"; std::cin >> num1 >> num2; for(i=1; i <= num1 && i <= num2; ++i) { // Checks if i is factor of both integers if(num1%i==0 && num2%i==0) gcd = i; } std::cout << \"G.C.D is \" << gcd << std::endl; return 0; } Figure 1. Source code of GCD program. Appropriate instrumentation will put a log statement at the beginning of each basic block. For simplicity, we add a print statement to write the number of the executed basic block in the console. In the GCD program, lines 6, 10, 13 shows the starting point of basic blocks. Therefore, the instrumented version of the GCD program is similar to the following code, in which print statement has been added manually: #include <stdio.h> #include <iostream> #include <fstream> std::ofstream logFile(\"log_file.txt\"); int main() { logFile << \"p1\" << std::endl; int num1, num2, i, gcd; std::cout << \"Enter two integers: \"; std::cin >> num1 >> num2; for(i=1; i <= num1 && i <= num2; ++i) { logFile << \"p2\" << std::endl; // Checks if i is factor of both integers if(num1%i==0 && num2%i==0) { logFile << \"p3\" << std::endl; gcd=i; } //continue; } std::cout << \"G.C.D is \" << gcd << std::endl; //return 0; logFile << \"p4\" << std::endl; } Figure 2. Source code of GCD program after instrumenting. One can see the cout statements added in lines 6, 12, 15, i.e., at the beginning of each basic block. For large programs, it is impossible to add such statements manually. To perform this instrumentation by ANTLR, we just need to identify conditional statements, including if statements, loop statements, and switch-case statements. Besides, the beginning of each function should be recognized. ANTLR provides a listener interface that consists of an enter method and exit method for each nonterminal in target language grammar. The listener can be passed to the parse tree walker used for traversing the parse tree in DFS . For instrumenting, we must implement the methods of listener interface related to conditional rules. The implementation of the listener interface in Python is shown in the following: class InstrumentationListener(CPP14Listener): def __init__(self, tokenized_source_code: CommonTokenStream): self.branch_number = 0 if tokenized_source_code is not None: # Move all the tokens in the source code in a buffer, token_stream_rewriter. self.token_stream_rewriter = TokenStreamRewriter.TokenStreamRewriter(tokenized_source_code) else: raise Exception(\u2018common_token_stream is None\u2019) # Creating and open a text file for logging the instrumentation result at beging of the program def enterTranslationunit(self, ctx: CPP14Parser.TranslationunitContext): new_code = '\\n #include <fstream> \\n std::ofstream logFile(\"log_file.txt\"); \\n' self.token_stream_rewriter.insertAfter(ctx.start.tokenIndex, new_code) # DFS traversal of a statement subtree, rooted at ctx and if the statement is a branching condition # insert a prob. def enterStatement(self, ctx: CPP14Parser.StatementContext): if isinstance(ctx.parentCtx, (CPP14Parser.SelectionstatementContext, CPP14Parser.IterationstatementContext)): # if there is a compound statement after the branchning condition: if isinstance(ctx.children[0], CPP14Parser.CompoundstatementContext): self.branch_number += 1 new_code = '\\n logFile << \"p' + str(self.branch_number) + '\" << endl; \\n' self.token_stream_rewriter.insertAfter(ctx.start.tokenIndex, new_code) # if there is only one statement after the branchning condition then create a block. elif not isinstance(ctx.children[0], (CPP14Parser.SelectionstatementContext, CPP14Parser.IterationstatementContext)): self.branch_number += 1 new_code = '{' new_code += '\\n logFile << \"p' + str(self.branch_number) + '\" << endl; \\n' new_code += ctx.getText() new_code += '\\n}' self.token_stream_rewriter.replaceRange(ctx.start.tokenIndex, ctx.stop.tokenIndex, new_code) def enterFunctionbody(self, ctx: CPP14Parser.FunctionbodyContext): self.branch_number += 1 new_code = '\\n logFile << \"p' + str(self.branch_number) + '\" << endl;\\n' self.token_stream_rewriter.insertAfter(ctx.start.tokenIndex, new_code) Figure 3. ANTLR listener for instrumenting. In the above code, class InstrumentationListener implements the interface CPP14Listener , which is the base listener for C++ grammar and generated by ANTLR. Note that the grammar of C++ 14 is available at ANTLR official website. Two methods enterStatement() and enterFunctionbody() are implemented to add a print statement in proper places of program code, respectively, at the beginning of each conditional statement and each function. These two methods are invoked by ANTLR parser tree walker if we pass an instance of InstrumnentationListerer to it. InstrumentationListener class also has two attributes: branch_number and token_stream_rewriter . branch_umber used to track the number of instrumented blocks during the instrumentation. Each time we add a print statement, we increment the value of branch_number by one unit. Line 3 defines branch_number and initialize it with zero. token_stream_rewiter object is an instance of TokenStreamRewiter class, which is provided by ANTLR and contain the stream of source code tokens. TokenStreamRewriter initializes with common_token_stream, which already has been built by ANTLR from the lexer class and then provides methods for adding and manipulating code snips within a given stream. Line 5 creates an instance of TokenStreamRewriter class to access its required methods. If common_token_stream is none, then an exception raises (Line 7). Let explain the logic of enterFunctionbody() as it seems to be simpler than enterStatement() . Each time a function definition occurred in the source code, this method is invoked. First, the branch_number will be increased by 1 (Line 25). At line 26, the print statement, including the branch_number is prepared, and then at Line 27, we tell token_stream_rewiter to insert this new code after the current beginning function token, i.e. , { in C++. For adding print after conditional and loop statements, more effort is required. enterStatement() is invoked each time that a statement node is visited. Line 10 checks to see if the statement is an instance of SelectionsteatemetContext or IterationstatementContext , which are relevant rule contexts for conditional and loop statements in C++ grammar. If this condition is not valid, i.e. , for regular statements, no action will perform. Otherwise, we are faced with two different situations. The first one (Line 11) is that the body of the conditional or loop statement is a compound statement, i.e., it has more than one statement, which encloses between two braces { and } . In such a case, we just need to add our print statement at the beginning of the compound statement right after token { . The code of this condition is exactly the same code used in enterFunctionbody() . The second situation occurs when the conditional or loop statement has only one statement inside its basic block. In this state, only the first statement is considered within the condition or loop by the compiler. If one adds a print statement without any enclosing brace, the execution path will not be captured correctly. Hence, in Line 15, after detecting that the statement is neither a compound statement nor branch, the proper code will be provided. The required code for instrumenting includes a left brace, a print statement, a current statement or context, and at the end, a right brace. Line 22 adds new_code to the current source code. Now the implementation of our InstrumentationListener has been finished. The next step is to write the main driver for the instrumentation tool and connect this listener to the parse tree walker. Figure 4 shows the body of the main python script required to create and run our efficient yet straightforward instrumenting tool. A comment line has explained each line of code, and therefore we omit extra descriptions. The only important note is that the instrumented code, i.e. , the modified source code, is accessible by token_stream_rewirter object. The getDefualtText() of token_stream_rewirter object is called to retrieve the new source code in Line 18. from antlr4 import * # Step 1: Convert input to a byte stream stream = InputStream(input_string) # Step 2: Create lexer lexer = test_v2Lexer(stream) # Step 3: Create a list of tokens token_stream = CommonTokenStream(lexer) # Step 4: Create parser parser = test_v2Parser(token_stream) # Step 5: Create parse tree parse_tree = parser.start() # Step 6: Adding a listener instrument_listener = InstrumentationListener(common_token_stream=self.common_token_stream) # Step 7: Create parse tree walker walker = ParseTreeWalker() # Step 8: Walk parse tree, attaching the listener to instrumented_programs the code walker.walk(listener=instrument_listener, t=parse_tree) # Step 9: new_source_code = instrument_listener.token_stream_rewriter.getDefaultText() print(new_source_code) Figure 4. The driver code for instrumenting. After the instrumenting was completed, the program must be compiled then executed to apply the modification. Figure 5 shows an example of executing with a sample input. As shown in Figure 5, the executed path for inputs 24 and 18 are logged into the console, in addition to the program output, which is 6 in this example. The sequence of the printed path shows the order in which basic blocks were executed. We may change the instrumentation to capture more complicated information about runtime. However, the techniques and principles will be the same used in this simple example. Interested readers may find more exercise about instrumentation at the end of this chapter. Figure 5. An example of executing the GCD program after instrumenting. Conclusion We show that using the ANTLR listener mechanism; it would be very simple to instrument the real-world CPP programs. A similar technique can be used to instrument the source code written in other programming languages such as Java and C#. In the next tutorial , we discuss using ANTLR for static analysis of the source code and computing some source code metrics.","title":"Program instrumentation"},{"location":"tutorials/program_instrumentation/#program-instrumentation","text":"By: Morteza Zakeri Last update: July 19, 2020 Edition 1 In this tutorial we describe a primary task in source code transformation, i.e. , program instrumentation, which is one of the CodA features. The task can be performed by properly applying compiler techniques, adding required code snippets at specific source code places. Instrumentation is the fundamental prerequisite for almost all dynamic analysis types. Let us begin with a simple case in which the purpose of instrumentation is to log the executed path of the program control flow graph for each execution. Consider the following C++ program used to calculate the greatest common divider (GCD) of two integers: #include <stdio.h> #include <iostream> int main() { int num1, num2, i, gcd; std::cout << \"Enter two integers: \"; std::cin >> num1 >> num2; for(i=1; i <= num1 && i <= num2; ++i) { // Checks if i is factor of both integers if(num1%i==0 && num2%i==0) gcd = i; } std::cout << \"G.C.D is \" << gcd << std::endl; return 0; } Figure 1. Source code of GCD program. Appropriate instrumentation will put a log statement at the beginning of each basic block. For simplicity, we add a print statement to write the number of the executed basic block in the console. In the GCD program, lines 6, 10, 13 shows the starting point of basic blocks. Therefore, the instrumented version of the GCD program is similar to the following code, in which print statement has been added manually: #include <stdio.h> #include <iostream> #include <fstream> std::ofstream logFile(\"log_file.txt\"); int main() { logFile << \"p1\" << std::endl; int num1, num2, i, gcd; std::cout << \"Enter two integers: \"; std::cin >> num1 >> num2; for(i=1; i <= num1 && i <= num2; ++i) { logFile << \"p2\" << std::endl; // Checks if i is factor of both integers if(num1%i==0 && num2%i==0) { logFile << \"p3\" << std::endl; gcd=i; } //continue; } std::cout << \"G.C.D is \" << gcd << std::endl; //return 0; logFile << \"p4\" << std::endl; } Figure 2. Source code of GCD program after instrumenting. One can see the cout statements added in lines 6, 12, 15, i.e., at the beginning of each basic block. For large programs, it is impossible to add such statements manually. To perform this instrumentation by ANTLR, we just need to identify conditional statements, including if statements, loop statements, and switch-case statements. Besides, the beginning of each function should be recognized. ANTLR provides a listener interface that consists of an enter method and exit method for each nonterminal in target language grammar. The listener can be passed to the parse tree walker used for traversing the parse tree in DFS . For instrumenting, we must implement the methods of listener interface related to conditional rules. The implementation of the listener interface in Python is shown in the following: class InstrumentationListener(CPP14Listener): def __init__(self, tokenized_source_code: CommonTokenStream): self.branch_number = 0 if tokenized_source_code is not None: # Move all the tokens in the source code in a buffer, token_stream_rewriter. self.token_stream_rewriter = TokenStreamRewriter.TokenStreamRewriter(tokenized_source_code) else: raise Exception(\u2018common_token_stream is None\u2019) # Creating and open a text file for logging the instrumentation result at beging of the program def enterTranslationunit(self, ctx: CPP14Parser.TranslationunitContext): new_code = '\\n #include <fstream> \\n std::ofstream logFile(\"log_file.txt\"); \\n' self.token_stream_rewriter.insertAfter(ctx.start.tokenIndex, new_code) # DFS traversal of a statement subtree, rooted at ctx and if the statement is a branching condition # insert a prob. def enterStatement(self, ctx: CPP14Parser.StatementContext): if isinstance(ctx.parentCtx, (CPP14Parser.SelectionstatementContext, CPP14Parser.IterationstatementContext)): # if there is a compound statement after the branchning condition: if isinstance(ctx.children[0], CPP14Parser.CompoundstatementContext): self.branch_number += 1 new_code = '\\n logFile << \"p' + str(self.branch_number) + '\" << endl; \\n' self.token_stream_rewriter.insertAfter(ctx.start.tokenIndex, new_code) # if there is only one statement after the branchning condition then create a block. elif not isinstance(ctx.children[0], (CPP14Parser.SelectionstatementContext, CPP14Parser.IterationstatementContext)): self.branch_number += 1 new_code = '{' new_code += '\\n logFile << \"p' + str(self.branch_number) + '\" << endl; \\n' new_code += ctx.getText() new_code += '\\n}' self.token_stream_rewriter.replaceRange(ctx.start.tokenIndex, ctx.stop.tokenIndex, new_code) def enterFunctionbody(self, ctx: CPP14Parser.FunctionbodyContext): self.branch_number += 1 new_code = '\\n logFile << \"p' + str(self.branch_number) + '\" << endl;\\n' self.token_stream_rewriter.insertAfter(ctx.start.tokenIndex, new_code) Figure 3. ANTLR listener for instrumenting. In the above code, class InstrumentationListener implements the interface CPP14Listener , which is the base listener for C++ grammar and generated by ANTLR. Note that the grammar of C++ 14 is available at ANTLR official website. Two methods enterStatement() and enterFunctionbody() are implemented to add a print statement in proper places of program code, respectively, at the beginning of each conditional statement and each function. These two methods are invoked by ANTLR parser tree walker if we pass an instance of InstrumnentationListerer to it. InstrumentationListener class also has two attributes: branch_number and token_stream_rewriter . branch_umber used to track the number of instrumented blocks during the instrumentation. Each time we add a print statement, we increment the value of branch_number by one unit. Line 3 defines branch_number and initialize it with zero. token_stream_rewiter object is an instance of TokenStreamRewiter class, which is provided by ANTLR and contain the stream of source code tokens. TokenStreamRewriter initializes with common_token_stream, which already has been built by ANTLR from the lexer class and then provides methods for adding and manipulating code snips within a given stream. Line 5 creates an instance of TokenStreamRewriter class to access its required methods. If common_token_stream is none, then an exception raises (Line 7). Let explain the logic of enterFunctionbody() as it seems to be simpler than enterStatement() . Each time a function definition occurred in the source code, this method is invoked. First, the branch_number will be increased by 1 (Line 25). At line 26, the print statement, including the branch_number is prepared, and then at Line 27, we tell token_stream_rewiter to insert this new code after the current beginning function token, i.e. , { in C++. For adding print after conditional and loop statements, more effort is required. enterStatement() is invoked each time that a statement node is visited. Line 10 checks to see if the statement is an instance of SelectionsteatemetContext or IterationstatementContext , which are relevant rule contexts for conditional and loop statements in C++ grammar. If this condition is not valid, i.e. , for regular statements, no action will perform. Otherwise, we are faced with two different situations. The first one (Line 11) is that the body of the conditional or loop statement is a compound statement, i.e., it has more than one statement, which encloses between two braces { and } . In such a case, we just need to add our print statement at the beginning of the compound statement right after token { . The code of this condition is exactly the same code used in enterFunctionbody() . The second situation occurs when the conditional or loop statement has only one statement inside its basic block. In this state, only the first statement is considered within the condition or loop by the compiler. If one adds a print statement without any enclosing brace, the execution path will not be captured correctly. Hence, in Line 15, after detecting that the statement is neither a compound statement nor branch, the proper code will be provided. The required code for instrumenting includes a left brace, a print statement, a current statement or context, and at the end, a right brace. Line 22 adds new_code to the current source code. Now the implementation of our InstrumentationListener has been finished. The next step is to write the main driver for the instrumentation tool and connect this listener to the parse tree walker. Figure 4 shows the body of the main python script required to create and run our efficient yet straightforward instrumenting tool. A comment line has explained each line of code, and therefore we omit extra descriptions. The only important note is that the instrumented code, i.e. , the modified source code, is accessible by token_stream_rewirter object. The getDefualtText() of token_stream_rewirter object is called to retrieve the new source code in Line 18. from antlr4 import * # Step 1: Convert input to a byte stream stream = InputStream(input_string) # Step 2: Create lexer lexer = test_v2Lexer(stream) # Step 3: Create a list of tokens token_stream = CommonTokenStream(lexer) # Step 4: Create parser parser = test_v2Parser(token_stream) # Step 5: Create parse tree parse_tree = parser.start() # Step 6: Adding a listener instrument_listener = InstrumentationListener(common_token_stream=self.common_token_stream) # Step 7: Create parse tree walker walker = ParseTreeWalker() # Step 8: Walk parse tree, attaching the listener to instrumented_programs the code walker.walk(listener=instrument_listener, t=parse_tree) # Step 9: new_source_code = instrument_listener.token_stream_rewriter.getDefaultText() print(new_source_code) Figure 4. The driver code for instrumenting. After the instrumenting was completed, the program must be compiled then executed to apply the modification. Figure 5 shows an example of executing with a sample input. As shown in Figure 5, the executed path for inputs 24 and 18 are logged into the console, in addition to the program output, which is 6 in this example. The sequence of the printed path shows the order in which basic blocks were executed. We may change the instrumentation to capture more complicated information about runtime. However, the techniques and principles will be the same used in this simple example. Interested readers may find more exercise about instrumentation at the end of this chapter. Figure 5. An example of executing the GCD program after instrumenting.","title":"Program instrumentation"},{"location":"tutorials/program_instrumentation/#conclusion","text":"We show that using the ANTLR listener mechanism; it would be very simple to instrument the real-world CPP programs. A similar technique can be used to instrument the source code written in other programming languages such as Java and C#. In the next tutorial , we discuss using ANTLR for static analysis of the source code and computing some source code metrics.","title":"Conclusion"}]}